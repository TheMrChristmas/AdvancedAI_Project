{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3r2vH4NBib6JLKqkOSWkG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"u7zULkzSB2RB","executionInfo":{"status":"ok","timestamp":1744619698899,"user_tz":-120,"elapsed":669,"user":{"displayName":"Elias Christmas","userId":"05020824668584987002"}}},"outputs":[],"source":["import requests\n","\n","\n","def get_search_results(query, api_key, api_url):\n","    params = {\n","        \"q\": query,\n","        \"num\": 10,\n","        \"api_key\": api_key\n","    }\n","    response = requests.get(api_url, params=params)\n","    return response.json()\n"]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def get_relevant_results(news_title, search_titles, threshold=0.85):\n","    model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n","    news_vec = model.encode([news_title])\n","    search_vecs = model.encode(search_titles)\n","\n","    similarities = cosine_similarity(news_vec, search_vecs)[0]\n","    relevant_indices = [i for i, score in enumerate(similarities) if score >= threshold]\n","\n","    return relevant_indices, similarities\n"],"metadata":{"id":"8X3ywC1NDd-R","executionInfo":{"status":"ok","timestamp":1744619753889,"user_tz":-120,"elapsed":46933,"user":{"displayName":"Elias Christmas","userId":"05020824668584987002"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def annotate_credibility(search_results, credible_sources):\n","    for result in search_results:\n","        domain = result['domain']\n","        result['credible'] = domain in credible_sources\n","    return search_results\n"],"metadata":{"id":"X3iHfAwxDqjy","executionInfo":{"status":"ok","timestamp":1744619760323,"user_tz":-120,"elapsed":3,"user":{"displayName":"Elias Christmas","userId":"05020824668584987002"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def construct_prompt(article_title, retrieved_snippets, credibility_flags):\n","    prompt = \"You are a fake news detector AI.\\n\\n\"\n","    prompt += f\"News Title: {article_title}\\n\\n\"\n","    prompt += \"Relevant search results:\\n\"\n","\n","    for i, (snippet, cred) in enumerate(zip(retrieved_snippets, credibility_flags)):\n","        label = \"Credible\" if cred else \"Unverified\"\n","        prompt += f\"[{label}] Snippet {i+1}: {snippet}\\n\"\n","\n","    prompt += \"\\nDetermine if the original news article is real or fake. Justify your reasoning. Answer:\\n\"\n","    return prompt\n"],"metadata":{"id":"JyNPyZd3Duy-","executionInfo":{"status":"ok","timestamp":1744619763621,"user_tz":-120,"elapsed":5,"user":{"displayName":"Elias Christmas","userId":"05020824668584987002"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import openai  # if using OpenAI, or use Hugging Face or Bedrock SDK\n","\n","def classify_news(prompt):\n","    response = openai.ChatCompletion.create(\n","        model=\"mixtral-8x7b\",  # or substitute\n","        messages=[{\"role\": \"user\", \"content\": prompt}],\n","        temperature=0.7,\n","        max_tokens=500\n","    )\n","    return response['choices'][0]['message']['content']\n"],"metadata":{"id":"oVhzvNLRD1LP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load the dataset\n","df = pd.read_csv(\"news.csv\")\n","\n","# Prepare the labels\n","df[\"False/Truth\"] = df[\"False/Truth\"].map({\"real\": 1, \"fake\": 0})\n","y_true = df[\"False/Truth\"].tolist()\n","\n","# Extract article text\n","articles = df['text'].tolist()\n","\n","# Initialize a list for predictions\n","y_pred = []\n","\n","# Loop over articles and classify them\n","for article in articles:\n","    # Step 1: Retrieve search results based on the article title (or keywords from article)\n","    search_results = get_search_results(article, api_key, api_url)\n","\n","    # Step 2: Extract titles/snippets from search results\n","    search_titles = [result['title'] for result in search_results['results']]\n","    search_snippets = [result['snippet'] for result in search_results['results']]\n","\n","    # Step 3: Get relevant search results based on cosine similarity\n","    relevant_indices, _ = get_relevant_results(article, search_titles)\n","    retrieved_snippets = [search_snippets[i] for i in relevant_indices]\n","\n","    # Step 4: Annotate credibility (if a source is in the credible list)\n","    annotated_results = annotate_credibility(search_results['results'], credible_sources)\n","    credibility_flags = [result['credible'] for result in annotated_results if result['title'] in retrieved_snippets]\n","\n","    # Step 5: Build the prompt and classify the news article\n","    prompt = construct_prompt(article, retrieved_snippets, credibility_flags)\n","    result = classify_news(prompt)\n","\n","    # Step 6: Convert result to 1 (real) or 0 (fake)\n","    label = 1 if result.strip().lower() == \"real\" else 0\n","    y_pred.append(label)\n","\n","# Evaluate the model\n","print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n","print(\"Precision:\", precision_score(y_true, y_pred))\n","print(\"Recall:\", recall_score(y_true, y_pred))\n","print(\"F1 Score:\", f1_score(y_true, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"23kE4_ZDI7ZR","executionInfo":{"status":"error","timestamp":1744619770473,"user_tz":-120,"elapsed":1755,"user":{"displayName":"Elias Christmas","userId":"05020824668584987002"}},"outputId":"959c2452-4134-4f7a-e72f-e58de9d65526"},"execution_count":5,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'api_key' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-630b7ebd2562>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Step 1: Retrieve search results based on the article title (or keywords from article)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_search_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Step 2: Extract titles/snippets from search results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'api_key' is not defined"]}]}]}