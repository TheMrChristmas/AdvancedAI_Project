{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX-M_UCjm5F6"
   },
   "source": [
    "##### Step 1: Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1745572711702,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "z6UzjSkVhNo9",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "11f64ec5-72a7-44b4-b28d-4ffdfb89fc63"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/Constraint_Train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# If you want to see the first few real tweets\n",
    "print(df.head(50))\n",
    "print(len(df))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7a4U6wQmVug"
   },
   "source": [
    "##### Step 2: Preprocess the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.438464900Z",
     "start_time": "2025-04-25T12:01:08.921558Z"
    },
    "executionInfo": {
     "elapsed": 4899,
     "status": "ok",
     "timestamp": 1745572718383,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "3_KV3TnjhisV"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "inputs = tokenizer(\n",
    "    list(df['tweet']),\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RODueydrmZX0"
   },
   "source": [
    "##### Step 3: Prepare the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.443463800Z",
     "start_time": "2025-04-25T12:01:15.393330Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745572724881,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "WdFkA8fFO6Lq",
    "outputId": "c6cc87ca-8fc7-4be2-98fd-4b3e82c8bbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real' 'fake']\n",
      "0    real\n",
      "1    real\n",
      "2    fake\n",
      "3    real\n",
      "4    real\n",
      "5    real\n",
      "6    real\n",
      "7    fake\n",
      "8    fake\n",
      "9    fake\n",
      "Name: label, dtype: object\n",
      "label\n",
      "real    3360\n",
      "fake    3060\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())\n",
    "print(df['label'].head(10))\n",
    "print(df['label'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.443463800Z",
     "start_time": "2025-04-25T12:01:17.153902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745572726567,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "Bl6qLLHU5T1L",
    "outputId": "847d7d41-f0b7-41ba-f209-4c74bc482423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Map 'real'/'fake' to 1/0\n",
    "df['label'] = df['label'].map({'fake': 0, 'real': 1})\n",
    "\n",
    "# Step 2: Remove any NaNs that came from unmapped values\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Step 3: Convert labels to integers\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Step 4: Check the result\n",
    "print(df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.472971100Z",
     "start_time": "2025-04-25T12:01:21.413009Z"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1745572801410,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "zM6UYEA7kHZw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "labels = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58S0SvirnBKO"
   },
   "source": [
    "##### Step 5: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.473970400Z",
     "start_time": "2025-04-25T12:02:03.269237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27119,
     "status": "ok",
     "timestamp": 1745572860131,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "Cc4yLkcbncB2",
    "outputId": "0088b742-4eb3-4608-ea6c-fdf6983808dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss: 0.6704\n",
      "Loss: 0.7015\n",
      "Loss: 0.6494\n",
      "Loss: 0.6200\n",
      "Loss: 0.6001\n",
      "Loss: 0.5533\n",
      "Loss: 0.5396\n",
      "Loss: 0.5984\n",
      "Loss: 0.4442\n",
      "Loss: 0.6472\n",
      "Loss: 0.3948\n",
      "Loss: 0.4124\n",
      "Loss: 0.6437\n",
      "Loss: 0.5478\n",
      "Loss: 0.4082\n",
      "Loss: 0.3231\n",
      "Loss: 0.4878\n",
      "Loss: 0.4900\n",
      "Loss: 0.5173\n",
      "Loss: 0.2928\n",
      "Loss: 0.3440\n",
      "Loss: 0.3656\n",
      "Loss: 0.3997\n",
      "Loss: 0.3382\n",
      "Loss: 0.5586\n",
      "Loss: 0.4750\n",
      "Loss: 0.3946\n",
      "Loss: 0.3134\n",
      "Loss: 0.3240\n",
      "Loss: 0.3943\n",
      "Loss: 0.2930\n",
      "Loss: 0.5217\n",
      "Loss: 0.3647\n",
      "Loss: 0.5292\n",
      "Loss: 0.4592\n",
      "Loss: 0.2673\n",
      "Loss: 0.3355\n",
      "Loss: 0.3595\n",
      "Loss: 0.3627\n",
      "Loss: 0.3002\n",
      "Loss: 0.2691\n",
      "Loss: 0.3361\n",
      "Loss: 0.1959\n",
      "Loss: 0.4191\n",
      "Loss: 0.1430\n",
      "Loss: 0.3040\n",
      "Loss: 0.4626\n",
      "Loss: 0.7963\n",
      "Loss: 0.3097\n",
      "Loss: 0.2968\n",
      "Loss: 0.1919\n",
      "Loss: 0.1409\n",
      "Loss: 0.3122\n",
      "Loss: 0.2100\n",
      "Loss: 0.2353\n",
      "Loss: 0.1425\n",
      "Loss: 0.1730\n",
      "Loss: 0.1085\n",
      "Loss: 0.1365\n",
      "Loss: 0.1856\n",
      "Loss: 0.2005\n",
      "Loss: 0.0877\n",
      "Loss: 0.2966\n",
      "Loss: 0.1265\n",
      "Loss: 0.1264\n",
      "Loss: 0.3197\n",
      "Loss: 0.1610\n",
      "Loss: 0.0541\n",
      "Loss: 0.3908\n",
      "Loss: 0.1162\n",
      "Loss: 0.2759\n",
      "Loss: 0.6199\n",
      "Loss: 0.1476\n",
      "Loss: 0.0734\n",
      "Loss: 0.2525\n",
      "Loss: 0.3042\n",
      "Loss: 0.3149\n",
      "Loss: 0.3043\n",
      "Loss: 0.1781\n",
      "Loss: 0.2769\n",
      "Loss: 0.1716\n",
      "Loss: 0.0926\n",
      "Loss: 0.1070\n",
      "Loss: 0.1414\n",
      "Loss: 0.4203\n",
      "Loss: 0.2977\n",
      "Loss: 0.1489\n",
      "Loss: 0.1901\n",
      "Loss: 0.2644\n",
      "Loss: 0.0745\n",
      "Loss: 0.0871\n",
      "Loss: 0.1394\n",
      "Loss: 0.0956\n",
      "Loss: 0.1540\n",
      "Loss: 0.0535\n",
      "Loss: 0.2904\n",
      "Loss: 0.0893\n",
      "Loss: 0.3612\n",
      "Loss: 0.0730\n",
      "Loss: 0.0573\n",
      "Loss: 0.0614\n",
      "Loss: 0.2338\n",
      "Loss: 0.0766\n",
      "Loss: 0.1966\n",
      "Loss: 0.1192\n",
      "Loss: 0.2600\n",
      "Loss: 0.5780\n",
      "Loss: 0.1085\n",
      "Loss: 0.1191\n",
      "Loss: 0.1615\n",
      "Loss: 0.0611\n",
      "Loss: 0.0686\n",
      "Loss: 0.2525\n",
      "Loss: 0.0945\n",
      "Loss: 0.0372\n",
      "Loss: 0.2053\n",
      "Loss: 0.2009\n",
      "Loss: 0.0640\n",
      "Loss: 0.0353\n",
      "Loss: 0.2315\n",
      "Loss: 0.1914\n",
      "Loss: 0.2485\n",
      "Loss: 0.1590\n",
      "Loss: 0.1145\n",
      "Loss: 0.0901\n",
      "Loss: 0.3121\n",
      "Loss: 0.0933\n",
      "Loss: 0.2291\n",
      "Loss: 0.2820\n",
      "Loss: 0.0780\n",
      "Loss: 0.3302\n",
      "Loss: 0.1431\n",
      "Loss: 0.0251\n",
      "Loss: 0.1258\n",
      "Loss: 0.1436\n",
      "Loss: 0.0485\n",
      "Loss: 0.4421\n",
      "Loss: 0.0743\n",
      "Loss: 0.3505\n",
      "Loss: 0.1539\n",
      "Loss: 0.1030\n",
      "Loss: 0.0767\n",
      "Loss: 0.1098\n",
      "Loss: 0.0393\n",
      "Loss: 0.1863\n",
      "Loss: 0.0477\n",
      "Loss: 0.1461\n",
      "Loss: 0.0757\n",
      "Loss: 0.2868\n",
      "Loss: 0.0652\n",
      "Loss: 0.1697\n",
      "Loss: 0.0493\n",
      "Loss: 0.0324\n",
      "Loss: 0.2080\n",
      "Loss: 0.1250\n",
      "Loss: 0.0792\n",
      "Loss: 0.0654\n",
      "Loss: 0.1056\n",
      "Loss: 0.1174\n",
      "Loss: 0.2338\n",
      "Loss: 0.0303\n",
      "Loss: 0.5154\n",
      "Loss: 0.3175\n",
      "Loss: 0.0387\n",
      "Loss: 0.0338\n",
      "Loss: 0.1407\n",
      "Loss: 0.0169\n",
      "Loss: 0.4222\n",
      "Loss: 0.1603\n",
      "Loss: 0.3011\n",
      "Loss: 0.3417\n",
      "Loss: 0.0434\n",
      "Loss: 0.0523\n",
      "Loss: 0.1439\n",
      "Loss: 0.1161\n",
      "Loss: 0.0309\n",
      "Loss: 0.1779\n",
      "Loss: 0.0696\n",
      "Loss: 0.0442\n",
      "Loss: 0.0555\n",
      "Loss: 0.0246\n",
      "Loss: 0.0499\n",
      "Loss: 0.4383\n",
      "Loss: 0.0293\n",
      "Loss: 0.1165\n",
      "Loss: 0.0736\n",
      "Loss: 0.0258\n",
      "Loss: 0.0731\n",
      "Loss: 0.2016\n",
      "Loss: 0.0818\n",
      "Loss: 0.0679\n",
      "Loss: 0.4705\n",
      "Loss: 0.1674\n",
      "Loss: 0.1151\n",
      "Loss: 0.0206\n",
      "Loss: 0.0810\n",
      "Loss: 0.1882\n",
      "Loss: 0.1051\n",
      "Loss: 0.0857\n",
      "Loss: 0.1286\n",
      "Loss: 0.0740\n",
      "Loss: 0.1122\n",
      "Loss: 0.1723\n",
      "Loss: 0.1872\n",
      "Loss: 0.2078\n",
      "Loss: 0.4149\n",
      "Loss: 0.0529\n",
      "Loss: 0.0266\n",
      "Loss: 0.0635\n",
      "Loss: 0.0723\n",
      "Loss: 0.0298\n",
      "Loss: 0.1098\n",
      "Loss: 0.0588\n",
      "Loss: 0.0517\n",
      "Loss: 0.5508\n",
      "Loss: 0.0631\n",
      "Loss: 0.1845\n",
      "Loss: 0.1902\n",
      "Loss: 0.0279\n",
      "Loss: 0.1733\n",
      "Loss: 0.1993\n",
      "Loss: 0.3208\n",
      "Loss: 0.0394\n",
      "Loss: 0.1690\n",
      "Loss: 0.0851\n",
      "Loss: 0.1703\n",
      "Loss: 0.0288\n",
      "Loss: 0.1139\n",
      "Loss: 0.1145\n",
      "Loss: 0.0291\n",
      "Loss: 0.1649\n",
      "Loss: 0.0846\n",
      "Loss: 0.0171\n",
      "Loss: 0.0789\n",
      "Loss: 0.0709\n",
      "Loss: 0.1059\n",
      "Loss: 0.3350\n",
      "Loss: 0.0354\n",
      "Loss: 0.0462\n",
      "Loss: 0.0352\n",
      "Loss: 0.0587\n",
      "Loss: 0.0414\n",
      "Loss: 0.0383\n",
      "Loss: 0.1025\n",
      "Loss: 0.0186\n",
      "Loss: 0.1071\n",
      "Loss: 0.2766\n",
      "Loss: 0.1802\n",
      "Loss: 0.1831\n",
      "Loss: 0.1981\n",
      "Loss: 0.0461\n",
      "Loss: 0.1158\n",
      "Loss: 0.2786\n",
      "Loss: 0.0262\n",
      "Loss: 0.0713\n",
      "Loss: 0.1311\n",
      "Loss: 0.0127\n",
      "Loss: 0.0367\n",
      "Loss: 0.0119\n",
      "Loss: 0.0851\n",
      "Loss: 0.4822\n",
      "Loss: 0.0449\n",
      "Loss: 0.3258\n",
      "Loss: 0.0539\n",
      "Loss: 0.0292\n",
      "Loss: 0.1249\n",
      "Loss: 0.0682\n",
      "Loss: 0.0595\n",
      "Loss: 0.0778\n",
      "Loss: 0.1474\n",
      "Loss: 0.1664\n",
      "Loss: 0.3073\n",
      "Loss: 0.0809\n",
      "Loss: 0.0150\n",
      "Loss: 0.0656\n",
      "Loss: 0.0287\n",
      "Loss: 0.0360\n",
      "Loss: 0.0246\n",
      "Loss: 0.0259\n",
      "Loss: 0.0655\n",
      "Loss: 0.0199\n",
      "Loss: 0.0734\n",
      "Loss: 0.9148\n",
      "Loss: 0.0297\n",
      "Loss: 0.0332\n",
      "Loss: 0.6780\n",
      "Loss: 0.0152\n",
      "Loss: 0.2360\n",
      "Loss: 0.2221\n",
      "Loss: 0.2527\n",
      "Loss: 0.1516\n",
      "Loss: 0.1158\n",
      "Loss: 0.0591\n",
      "Loss: 0.2862\n",
      "Loss: 0.0267\n",
      "Loss: 0.0714\n",
      "Loss: 0.0392\n",
      "Loss: 0.0913\n",
      "Loss: 0.0291\n",
      "Loss: 0.1539\n",
      "Loss: 0.1383\n",
      "Loss: 0.0505\n",
      "Loss: 0.0433\n",
      "Loss: 0.1313\n",
      "Loss: 0.1045\n",
      "Loss: 0.0458\n",
      "Loss: 0.0202\n",
      "Loss: 0.1458\n",
      "Loss: 0.0758\n",
      "Loss: 0.0497\n",
      "Loss: 0.0129\n",
      "Loss: 0.0843\n",
      "Loss: 0.0834\n",
      "Loss: 0.0301\n",
      "Loss: 0.0369\n",
      "Loss: 0.1177\n",
      "Loss: 0.0181\n",
      "Loss: 0.0338\n",
      "Loss: 0.0605\n",
      "Loss: 0.0703\n",
      "Loss: 0.0958\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Assuming train_loader is already defined\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Assign higher weight to class 0 (fake), lower to class 1 (true)\n",
    "# Adjust as needed (e.g., [2.0, 1.0] or [3.0, 1.0] for stronger penalty on false negatives)\n",
    "class_weights = torch.tensor([5.0, 1.0]).to(device)\n",
    "loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):  # Adjust as needed\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fct(logits, labels)  # manual loss with weight\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9611\n",
      "Precision: 0.9956\n",
      "Recall: 0.9301\n",
      "F1-Score: 0.9617\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.93      1.00      0.96      2434\n",
      "        True       1.00      0.93      0.96      2702\n",
      "\n",
      "    accuracy                           0.96      5136\n",
      "   macro avg       0.96      0.96      0.96      5136\n",
      "weighted avg       0.96      0.96      0.96      5136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Fake\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh1sObxtQJjk"
   },
   "source": [
    "##### Step 6: Predict on a new tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745573283877,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "-61kBy69QI9B"
   },
   "outputs": [],
   "source": [
    "def predict(tweet):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        return \"True\" if predicted_class == 1 else \"False\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9424\n",
      "Precision: 0.9867\n",
      "Recall: 0.8997\n",
      "F1-Score: 0.9412\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.90      0.99      0.94       626\n",
      "        True       0.99      0.90      0.94       658\n",
      "\n",
      "    accuracy                           0.94      1284\n",
      "   macro avg       0.95      0.94      0.94      1284\n",
      "weighted avg       0.95      0.94      0.94      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Fake\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on a false tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745573285667,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "9z4eGpmRQbU5",
    "outputId": "328d8d08-03de-42a6-f1d2-4eefa37a6c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n"
     ]
    }
   ],
   "source": [
    "example_tweet = \"Breaking news: Chocolate can cure COVID!\"\n",
    "result = predict(example_tweet)\n",
    "print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on a factual tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1745573287134,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "yyRGOk6pQlEs",
    "outputId": "fe1ea81e-ab63-41e8-d11f-e8ddbaa61585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n"
     ]
    }
   ],
   "source": [
    "factual_tweet = \"The COVID-19 vaccine helps reduce the severity of symptoms and the risk of hospitalization.\"\n",
    "result = predict(factual_tweet)\n",
    "print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Missing file: C:\\Users\\elias\\.cache\\huggingface\\gradio\\frpc\\frpc_windows_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.3\n",
      "3. Move the file to this location: C:\\Users\\elias\\.cache\\huggingface\\gradio\\frpc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Type your tweet here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Fake news Predictor\",\n",
    "    description=\"Enter a tweet and let the model classify it as factual or fake\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPy4nlYYZJlHhoIYmB+FVgJ",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0323dc2779054d8a9ab4e9e0aa7076c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b3c34734fc7438696c390f42025926d",
       "IPY_MODEL_f66ef9e968284570a091a44e1bec4f1b",
       "IPY_MODEL_caca60bb0bc64f7bba28b59a35c16ac0"
      ],
      "layout": "IPY_MODEL_2a506eea84d44b5fbc4bdf56f0174811"
     }
    },
    "2a506eea84d44b5fbc4bdf56f0174811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c72947b3ba4385aa4eb4656d6fb4d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b3c34734fc7438696c390f42025926d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e01f95c65fc24ff3806df45dc3c15803",
      "placeholder": "​",
      "style": "IPY_MODEL_39c72947b3ba4385aa4eb4656d6fb4d0",
      "value": "model.safetensors: 100%"
     }
    },
    "5b73fe905e79467d9ec5f9be612c3480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2cd2fc7f6d743bdb00df0668e9d91e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caca60bb0bc64f7bba28b59a35c16ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f525452fa6c9402a99910f3981c33f08",
      "placeholder": "​",
      "style": "IPY_MODEL_b2cd2fc7f6d743bdb00df0668e9d91e4",
      "value": " 440M/440M [00:01&lt;00:00, 275MB/s]"
     }
    },
    "cd947bea1c8a4f4db09393c6c948affe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e01f95c65fc24ff3806df45dc3c15803": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f525452fa6c9402a99910f3981c33f08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66ef9e968284570a091a44e1bec4f1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd947bea1c8a4f4db09393c6c948affe",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b73fe905e79467d9ec5f9be612c3480",
      "value": 440449768
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
