{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX-M_UCjm5F6"
   },
   "source": [
    "##### 1: Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1745572711702,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "z6UzjSkVhNo9",
    "jupyter": {
     "is_executing": true
    },
    "outputId": "11f64ec5-72a7-44b4-b28d-4ffdfb89fc63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                                              tweet label\n",
      "0    1  The CDC currently reports 99031 deaths. In gen...  real\n",
      "1    2  States reported 1121 deaths a small rise from ...  real\n",
      "2    3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
      "3    4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
      "4    5  Populous states can generate large case counts...  real\n",
      "5    6  Covid Act Now found \"on average each person in...  real\n",
      "6    7  If you tested positive for #COVID19 and have n...  real\n",
      "7    8  Obama Calls Trump’s Coronavirus Response A Cha...  fake\n",
      "8    9  ???Clearly, the Obama administration did not l...  fake\n",
      "9   10  Retraction—Hydroxychloroquine or chloroquine w...  fake\n",
      "10  11  Take simple daily precautions to help prevent ...  real\n",
      "11  12  The NBA is poised to restart this month. In Ma...  fake\n",
      "12  13  We just announced that the first participants ...  real\n",
      "13  14  #CoronaVirusUpdates #IndiaFightsCorona More th...  real\n",
      "14  15  Protect yourself and others from #COVID19 when...  real\n",
      "15  16  As of 18 August 2020 8AM till now there have b...  real\n",
      "16  17  Because of Donald Trump's negligence and incom...  fake\n",
      "17  18  #IndiaFightsCorona India continues to scale ne...  real\n",
      "18  19  We just announced that we have shipped vials o...  real\n",
      "19  20  Multiple Facebook posts claim that “Aussies wi...  fake\n",
      "20  21  No Nobel Prize laureate Tasuku Honjo didn't sa...  fake\n",
      "21  22  The NZ COVID Tracker app will remain important...  real\n",
      "22  23  BREAKING NEWS# The president Cryill Ramaphosa ...  fake\n",
      "23  24  We are delighted that 78 high- and upper-middl...  real\n",
      "24  25  Very intriguing possibility that mood changes ...  real\n",
      "25  26  Elon Musck To New Baby; Get A Job Kid! https:/...  fake\n",
      "26  27  _A new alcohol-free sanitizer has been develop...  fake\n",
      "27  28  Just Appendix B gathering all the state orders...  real\n",
      "28  29  Yesterday our laboratories completed 2899 test...  real\n",
      "29  30  Reusing #N95 masks? NIH found vaporized hydrog...  real\n",
      "30  31  .@realDonaldTrump has shifted his focus at dif...  fake\n",
      "31  32  Doctored image of President Donald Trump share...  fake\n",
      "32  33  This #FourthOfJuly weekend if you choose to sp...  real\n",
      "33  34  CDC Recommends Mothers Stop Breastfeeding To B...  fake\n",
      "34  35  Singapore Airlines Haults All Flights Due To C...  fake\n",
      "35  36  Florida Governor Ron DeSantis Botches COVID-19...  fake\n",
      "36  37  We apologise to the Government of Ekiti State ...  real\n",
      "37  38  NYT invented the video of a doctor fighting co...  fake\n",
      "38  39  In May we did not break 30k cases in a day. To...  real\n",
      "39  40  ALERT: Americans With Coronavirus Symptoms Are...  fake\n",
      "40  41  We launched the #COVID19 Solidarity Response F...  real\n",
      "41  42  Football player Cristiano Ronaldo turned all h...  fake\n",
      "42  43  including that there will again be testing of ...  real\n",
      "43  44  I don't want to do a national lockdown again.'...  real\n",
      "44  45  Our daily update is published. States reported...  real\n",
      "45  46  #IndiaFightsCorona New Recoveries in India hav...  real\n",
      "46  47  The top 5 States with high Active Caseload are...  real\n",
      "47  48  There are currently 4927 people in managed iso...  real\n",
      "48  49  Schools are struggling to cope with a lack of ...  real\n",
      "49  50  Scientists at AstraZeneca complain their work ...  fake\n",
      "6420\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/Constraint_Train.csv\")\n",
    "\n",
    "\n",
    "\n",
    "# If you want to see the first few real tweets\n",
    "print(df.head(50))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u7a4U6wQmVug"
   },
   "source": [
    "##### 2: Preprocess the text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.438464900Z",
     "start_time": "2025-04-25T12:01:08.921558Z"
    },
    "executionInfo": {
     "elapsed": 4899,
     "status": "ok",
     "timestamp": 1745572718383,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "3_KV3TnjhisV"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the texts\n",
    "inputs = tokenizer(\n",
    "    list(df['tweet']),\n",
    "    return_tensors='pt',\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RODueydrmZX0"
   },
   "source": [
    "##### 3: Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.1: Prepare the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.443463800Z",
     "start_time": "2025-04-25T12:01:15.393330Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1745572724881,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "WdFkA8fFO6Lq",
    "outputId": "c6cc87ca-8fc7-4be2-98fd-4b3e82c8bbb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['real' 'fake']\n",
      "0    real\n",
      "1    real\n",
      "2    fake\n",
      "3    real\n",
      "4    real\n",
      "5    real\n",
      "6    real\n",
      "7    fake\n",
      "8    fake\n",
      "9    fake\n",
      "Name: label, dtype: object\n",
      "label\n",
      "real    3360\n",
      "fake    3060\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['label'].unique())\n",
    "print(df['label'].head(10))\n",
    "print(df['label'].value_counts(dropna=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.443463800Z",
     "start_time": "2025-04-25T12:01:17.153902Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1745572726567,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "Bl6qLLHU5T1L",
    "outputId": "847d7d41-f0b7-41ba-f209-4c74bc482423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Map 'real'/'fake' to 1/0\n",
    "df['label'] = df['label'].map({'fake': 0, 'real': 1})\n",
    "\n",
    "# Step 2: Remove any NaNs that came from unmapped values\n",
    "df = df.dropna(subset=['label'])\n",
    "\n",
    "# Step 3: Convert labels to integers\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# Step 4: Check the result\n",
    "print(df['label'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2: Splitting data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.472971100Z",
     "start_time": "2025-04-25T12:01:21.413009Z"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1745572801410,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "zM6UYEA7kHZw"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "labels = torch.tensor(df['label'].values, dtype=torch.long)\n",
    "\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4: BERT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58S0SvirnBKO"
   },
   "source": [
    "##### 4.1: Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-06T09:35:13.473970400Z",
     "start_time": "2025-04-25T12:02:03.269237Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 27119,
     "status": "ok",
     "timestamp": 1745572860131,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "Cc4yLkcbncB2",
    "outputId": "0088b742-4eb3-4608-ea6c-fdf6983808dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss: 0.7233\n",
      "Loss: 0.7145\n",
      "Loss: 0.5871\n",
      "Loss: 0.6546\n",
      "Loss: 0.5779\n",
      "Loss: 0.6660\n",
      "Loss: 0.5013\n",
      "Loss: 0.5587\n",
      "Loss: 0.4318\n",
      "Loss: 0.4487\n",
      "Loss: 0.4870\n",
      "Loss: 0.6037\n",
      "Loss: 0.7908\n",
      "Loss: 0.4646\n",
      "Loss: 0.4818\n",
      "Loss: 0.6415\n",
      "Loss: 0.3486\n",
      "Loss: 0.4744\n",
      "Loss: 0.5113\n",
      "Loss: 0.4524\n",
      "Loss: 0.6433\n",
      "Loss: 0.4207\n",
      "Loss: 0.5400\n",
      "Loss: 0.4523\n",
      "Loss: 0.3968\n",
      "Loss: 0.3330\n",
      "Loss: 0.3649\n",
      "Loss: 0.4895\n",
      "Loss: 0.4131\n",
      "Loss: 0.2792\n",
      "Loss: 0.3196\n",
      "Loss: 0.2356\n",
      "Loss: 0.3702\n",
      "Loss: 0.2940\n",
      "Loss: 0.2727\n",
      "Loss: 0.3282\n",
      "Loss: 0.4246\n",
      "Loss: 0.2354\n",
      "Loss: 0.2551\n",
      "Loss: 0.1835\n",
      "Loss: 0.2538\n",
      "Loss: 0.2855\n",
      "Loss: 0.2752\n",
      "Loss: 0.2899\n",
      "Loss: 0.3554\n",
      "Loss: 0.1614\n",
      "Loss: 0.1276\n",
      "Loss: 0.0747\n",
      "Loss: 0.3723\n",
      "Loss: 0.1984\n",
      "Loss: 0.1619\n",
      "Loss: 0.2006\n",
      "Loss: 0.1962\n",
      "Loss: 0.2409\n",
      "Loss: 0.1388\n",
      "Loss: 0.1474\n",
      "Loss: 0.2585\n",
      "Loss: 0.2591\n",
      "Loss: 0.2425\n",
      "Loss: 0.2229\n",
      "Loss: 0.4517\n",
      "Loss: 0.2630\n",
      "Loss: 0.1345\n",
      "Loss: 0.2185\n",
      "Loss: 0.0893\n",
      "Loss: 0.4263\n",
      "Loss: 0.0836\n",
      "Loss: 0.3428\n",
      "Loss: 0.0760\n",
      "Loss: 0.1715\n",
      "Loss: 0.1571\n",
      "Loss: 0.1526\n",
      "Loss: 0.1544\n",
      "Loss: 0.1430\n",
      "Loss: 0.1114\n",
      "Loss: 0.2910\n",
      "Loss: 0.1905\n",
      "Loss: 0.0570\n",
      "Loss: 0.1062\n",
      "Loss: 0.5427\n",
      "Loss: 0.1903\n",
      "Loss: 0.1900\n",
      "Loss: 0.3176\n",
      "Loss: 0.2973\n",
      "Loss: 0.1558\n",
      "Loss: 0.1467\n",
      "Loss: 0.1422\n",
      "Loss: 0.2667\n",
      "Loss: 0.0745\n",
      "Loss: 0.1871\n",
      "Loss: 0.1331\n",
      "Loss: 0.1306\n",
      "Loss: 0.1112\n",
      "Loss: 0.1582\n",
      "Loss: 0.1196\n",
      "Loss: 0.2094\n",
      "Loss: 0.2753\n",
      "Loss: 0.1120\n",
      "Loss: 0.0461\n",
      "Loss: 0.0378\n",
      "Loss: 0.1183\n",
      "Loss: 0.0458\n",
      "Loss: 0.1155\n",
      "Loss: 0.0467\n",
      "Loss: 0.1900\n",
      "Loss: 0.2740\n",
      "Loss: 0.0554\n",
      "Loss: 0.0768\n",
      "Loss: 0.1265\n",
      "Loss: 0.0584\n",
      "Loss: 0.2872\n",
      "Loss: 0.1855\n",
      "Loss: 0.1564\n",
      "Loss: 0.0748\n",
      "Loss: 0.2303\n",
      "Loss: 0.1079\n",
      "Loss: 0.1361\n",
      "Loss: 0.1365\n",
      "Loss: 0.0924\n",
      "Loss: 0.1922\n",
      "Loss: 0.0516\n",
      "Loss: 0.5382\n",
      "Loss: 0.1264\n",
      "Loss: 0.1890\n",
      "Loss: 0.2718\n",
      "Loss: 0.4827\n",
      "Loss: 0.0397\n",
      "Loss: 0.0474\n",
      "Loss: 0.0471\n",
      "Loss: 0.0584\n",
      "Loss: 0.1792\n",
      "Loss: 0.1721\n",
      "Loss: 0.0500\n",
      "Loss: 0.0822\n",
      "Loss: 0.0970\n",
      "Loss: 0.0433\n",
      "Loss: 0.0538\n",
      "Loss: 0.0836\n",
      "Loss: 0.3759\n",
      "Loss: 0.0355\n",
      "Loss: 0.2639\n",
      "Loss: 0.1275\n",
      "Loss: 0.0393\n",
      "Loss: 0.1388\n",
      "Loss: 0.0520\n",
      "Loss: 0.2474\n",
      "Loss: 0.1663\n",
      "Loss: 0.1059\n",
      "Loss: 0.0549\n",
      "Loss: 0.0834\n",
      "Loss: 0.0996\n",
      "Loss: 0.0432\n",
      "Loss: 0.0369\n",
      "Loss: 0.0488\n",
      "Loss: 0.2779\n",
      "Loss: 0.1037\n",
      "Loss: 0.2677\n",
      "Loss: 0.6516\n",
      "Loss: 0.0510\n",
      "Loss: 0.0831\n",
      "Loss: 0.0919\n",
      "Loss: 0.1355\n",
      "Loss: 0.1227\n",
      "Loss: 0.1709\n",
      "Loss: 0.0982\n",
      "Loss: 0.1975\n",
      "Loss: 0.2120\n",
      "Loss: 0.0876\n",
      "Loss: 0.0702\n",
      "Loss: 0.3942\n",
      "Loss: 0.2322\n",
      "Loss: 0.0426\n",
      "Loss: 0.1935\n",
      "Loss: 0.1285\n",
      "Loss: 0.0251\n",
      "Loss: 0.2681\n",
      "Loss: 0.1943\n",
      "Loss: 0.3512\n",
      "Loss: 0.5943\n",
      "Loss: 0.0516\n",
      "Loss: 0.0927\n",
      "Loss: 0.3927\n",
      "Loss: 0.0666\n",
      "Loss: 0.1100\n",
      "Loss: 0.1000\n",
      "Loss: 0.1155\n",
      "Loss: 0.2049\n",
      "Loss: 0.2231\n",
      "Loss: 0.2820\n",
      "Loss: 0.1622\n",
      "Loss: 0.0982\n",
      "Loss: 0.1160\n",
      "Loss: 0.0844\n",
      "Loss: 0.0923\n",
      "Loss: 0.1269\n",
      "Loss: 0.3519\n",
      "Loss: 0.1431\n",
      "Loss: 0.1484\n",
      "Loss: 0.2619\n",
      "Loss: 0.0854\n",
      "Loss: 0.0894\n",
      "Loss: 0.0464\n",
      "Loss: 0.0715\n",
      "Loss: 0.1184\n",
      "Loss: 0.0788\n",
      "Loss: 0.1124\n",
      "Loss: 0.0872\n",
      "Loss: 0.1157\n",
      "Loss: 0.1077\n",
      "Loss: 0.0511\n",
      "Loss: 0.1378\n",
      "Loss: 0.2753\n",
      "Loss: 0.0824\n",
      "Loss: 0.3999\n",
      "Loss: 0.2712\n",
      "Loss: 0.0280\n",
      "Loss: 0.0404\n",
      "Loss: 0.0954\n",
      "Loss: 0.0957\n",
      "Loss: 0.1738\n",
      "Loss: 0.1989\n",
      "Loss: 0.1323\n",
      "Loss: 0.1447\n",
      "Loss: 0.0907\n",
      "Loss: 0.0415\n",
      "Loss: 0.0150\n",
      "Loss: 0.0801\n",
      "Loss: 0.0503\n",
      "Loss: 0.0217\n",
      "Loss: 0.0733\n",
      "Loss: 0.0845\n",
      "Loss: 0.1278\n",
      "Loss: 0.2195\n",
      "Loss: 0.0286\n",
      "Loss: 0.1573\n",
      "Loss: 0.1610\n",
      "Loss: 0.0235\n",
      "Loss: 0.0592\n",
      "Loss: 0.0456\n",
      "Loss: 0.2604\n",
      "Loss: 0.0238\n",
      "Loss: 0.1186\n",
      "Loss: 0.0700\n",
      "Loss: 0.1394\n",
      "Loss: 0.2638\n",
      "Loss: 0.1874\n",
      "Loss: 0.0716\n",
      "Loss: 0.0297\n",
      "Loss: 0.2541\n",
      "Loss: 0.4202\n",
      "Loss: 0.0274\n",
      "Loss: 0.2970\n",
      "Loss: 0.0384\n",
      "Loss: 0.1819\n",
      "Loss: 0.1132\n",
      "Loss: 0.2572\n",
      "Loss: 0.0884\n",
      "Loss: 0.1271\n",
      "Loss: 0.0956\n",
      "Loss: 0.1501\n",
      "Loss: 0.0505\n",
      "Loss: 0.1835\n",
      "Loss: 0.0563\n",
      "Loss: 0.0372\n",
      "Loss: 0.0848\n",
      "Loss: 0.0655\n",
      "Loss: 0.0287\n",
      "Loss: 0.0398\n",
      "Loss: 0.1027\n",
      "Loss: 0.2627\n",
      "Loss: 0.0310\n",
      "Loss: 0.1004\n",
      "Loss: 0.1203\n",
      "Loss: 0.0488\n",
      "Loss: 0.1595\n",
      "Loss: 0.1430\n",
      "Loss: 0.0343\n",
      "Loss: 0.0372\n",
      "Loss: 0.0514\n",
      "Loss: 0.0197\n",
      "Loss: 0.3373\n",
      "Loss: 0.0911\n",
      "Loss: 0.1594\n",
      "Loss: 0.1369\n",
      "Loss: 0.1188\n",
      "Loss: 0.0779\n",
      "Loss: 0.1451\n",
      "Loss: 0.1321\n",
      "Loss: 0.8325\n",
      "Loss: 0.0495\n",
      "Loss: 0.1948\n",
      "Loss: 0.0515\n",
      "Loss: 0.0887\n",
      "Loss: 0.0298\n",
      "Loss: 0.0350\n",
      "Loss: 0.0209\n",
      "Loss: 0.4212\n",
      "Loss: 0.0838\n",
      "Loss: 0.1978\n",
      "Loss: 0.0680\n",
      "Loss: 0.0663\n",
      "Loss: 0.0950\n",
      "Loss: 0.0290\n",
      "Loss: 0.0514\n",
      "Loss: 0.0314\n",
      "Loss: 0.0425\n",
      "Loss: 0.0194\n",
      "Loss: 0.0763\n",
      "Loss: 0.0390\n",
      "Loss: 0.0525\n",
      "Loss: 0.0569\n",
      "Loss: 0.0419\n",
      "Loss: 0.0906\n",
      "Loss: 0.0321\n",
      "Loss: 0.1535\n",
      "Loss: 0.0122\n",
      "Loss: 0.0375\n",
      "Loss: 0.0750\n",
      "Loss: 0.0329\n",
      "Loss: 0.0426\n",
      "Loss: 0.0523\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "# Assuming train_loader is already defined\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Assign higher weight to class 0 (fake), lower to class 1 (true)\n",
    "# Adjust as needed (e.g., [2.0, 1.0] or [3.0, 1.0] for stronger penalty on false negatives)\n",
    "class_weights = torch.tensor([5.0, 1.0]).to(device)\n",
    "loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1):  # Adjust as needed\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fct(logits, labels)  # manual loss with weight\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        print(f\"Loss: {loss.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Fake\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5: Testing model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh1sObxtQJjk"
   },
   "source": [
    "##### 5.1: Predict on a new tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745573283877,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "-61kBy69QI9B"
   },
   "outputs": [],
   "source": [
    "def predict(tweet):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(tweet, return_tensors=\"pt\", truncation=True, padding=True, max_length=128).to(device)\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        predicted_class = torch.argmax(logits, dim=1).item()\n",
    "        return \"True\" if predicted_class == 1 else \"False\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2: Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9424\n",
      "Precision: 0.9867\n",
      "Recall: 0.8997\n",
      "F1-Score: 0.9412\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.90      0.99      0.94       626\n",
      "        True       0.99      0.90      0.94       658\n",
      "\n",
      "    accuracy                           0.94      1284\n",
      "   macro avg       0.95      0.94      0.94      1284\n",
      "weighted avg       0.95      0.94      0.94      1284\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predicted_labels.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='binary')\n",
    "recall = recall_score(true_labels, predicted_labels, average='binary')\n",
    "f1 = f1_score(true_labels, predicted_labels, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Optional: Full classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels, target_names=[\"Fake\", \"True\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on a false tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745573285667,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "9z4eGpmRQbU5",
    "outputId": "328d8d08-03de-42a6-f1d2-4eefa37a6c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n"
     ]
    }
   ],
   "source": [
    "example_tweet = \"Breaking news: Chocolate can cure COVID!\"\n",
    "result = predict(example_tweet)\n",
    "print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting on a factual tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1745573287134,
     "user": {
      "displayName": "Elias Christmas",
      "userId": "05020824668584987002"
     },
     "user_tz": -120
    },
    "id": "yyRGOk6pQlEs",
    "outputId": "fe1ea81e-ab63-41e8-d11f-e8ddbaa61585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: False\n"
     ]
    }
   ],
   "source": [
    "factual_tweet = \"The COVID-19 vaccine helps reduce the severity of symptoms and the risk of hospitalization.\"\n",
    "result = predict(factual_tweet)\n",
    "print(f\"Prediction: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Missing file: C:\\Users\\elias\\.cache\\huggingface\\gradio\\frpc\\frpc_windows_amd64_v0.3. \n",
      "\n",
      "Please check your internet connection. This can happen if your antivirus software blocks the download of this file. You can install manually by following these steps: \n",
      "\n",
      "1. Download this file: https://cdn-media.huggingface.co/frpc-gradio-0.3/frpc_windows_amd64.exe\n",
      "2. Rename the downloaded file to: frpc_windows_amd64_v0.3\n",
      "3. Move the file to this location: C:\\Users\\elias\\.cache\\huggingface\\gradio\\frpc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset file at: .gradio\\flagged\\dataset1.csv\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs=gr.Textbox(lines=2, placeholder=\"Type your tweet here...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Fake news Predictor\",\n",
    "    description=\"Enter a tweet and let the model classify it as factual or fake\"\n",
    ")\n",
    "\n",
    "iface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPy4nlYYZJlHhoIYmB+FVgJ",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0323dc2779054d8a9ab4e9e0aa7076c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b3c34734fc7438696c390f42025926d",
       "IPY_MODEL_f66ef9e968284570a091a44e1bec4f1b",
       "IPY_MODEL_caca60bb0bc64f7bba28b59a35c16ac0"
      ],
      "layout": "IPY_MODEL_2a506eea84d44b5fbc4bdf56f0174811"
     }
    },
    "2a506eea84d44b5fbc4bdf56f0174811": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c72947b3ba4385aa4eb4656d6fb4d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b3c34734fc7438696c390f42025926d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e01f95c65fc24ff3806df45dc3c15803",
      "placeholder": "​",
      "style": "IPY_MODEL_39c72947b3ba4385aa4eb4656d6fb4d0",
      "value": "model.safetensors: 100%"
     }
    },
    "5b73fe905e79467d9ec5f9be612c3480": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b2cd2fc7f6d743bdb00df0668e9d91e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "caca60bb0bc64f7bba28b59a35c16ac0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f525452fa6c9402a99910f3981c33f08",
      "placeholder": "​",
      "style": "IPY_MODEL_b2cd2fc7f6d743bdb00df0668e9d91e4",
      "value": " 440M/440M [00:01&lt;00:00, 275MB/s]"
     }
    },
    "cd947bea1c8a4f4db09393c6c948affe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e01f95c65fc24ff3806df45dc3c15803": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f525452fa6c9402a99910f3981c33f08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f66ef9e968284570a091a44e1bec4f1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cd947bea1c8a4f4db09393c6c948affe",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5b73fe905e79467d9ec5f9be612c3480",
      "value": 440449768
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
